{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4kwcJAah6S2",
        "outputId": "54e7ae51-bf9d-4765-d6b9-a8cee0961661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
            "py 3.7.13\n",
            "tf 2.8.2\n",
            "keras 2.8.0\n",
            "mem 12986.89453125\n",
            "cpu 2\n",
            "Compute dtype: float16\n",
            "Variable dtype: float32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\",\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "from platform import python_version\n",
        "import warnings\n",
        "import time\n",
        "import datetime as dt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import multiprocessing as mp\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "# from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.utils import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "import psutil\n",
        "import random\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_policy(policy)\n",
        "\n",
        "print(\"py\", python_version())\n",
        "print(\"tf\", tf.__version__)\n",
        "print(\"keras\", tf.keras.__version__)\n",
        "mem = psutil.virtual_memory()\n",
        "print(\"mem\", mem.total/1024/1024)\n",
        "cpu = mp.cpu_count()\n",
        "print(\"cpu\", cpu)\n",
        "print('Compute dtype: %s' % policy.compute_dtype)\n",
        "print('Variable dtype: %s' % policy.variable_dtype)\n",
        "\n",
        "%system nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TycCekrZjNfF",
        "outputId": "c624c8ad-031e-4b2e-e6b8-0f8b9f99ca7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "batch_size = 100\n",
        "testsplit = .2\n",
        "targetx = 224\n",
        "targety = 224\n",
        "learning_rate = 0.0001\n",
        "classes = 120\n",
        "seed = random.randint(1, 1000)\n",
        "\n",
        "data_dir = \"/kaggle/input/images/Images/\"\n",
        "annotations_dir = \"/kaggle/input/annotations/Annotation/\"\n",
        "cropped_dir = \"/kaggle/working/cropped/\""
      ],
      "metadata": {
        "id": "aKUDfDvFi1Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%system rm -rf $cropped_dir\n",
        "%system mkdir $cropped_dir\n",
        "\n",
        "def save_cropped_img(path, annotation, newpath):\n",
        "    tree = ET.parse(annotation)\n",
        "    xmin = int(tree.getroot().findall('.//xmin')[0].text)\n",
        "    xmax = int(tree.getroot().findall('.//xmax')[0].text)\n",
        "    ymin = int(tree.getroot().findall('.//ymin')[0].text)\n",
        "    ymax = int(tree.getroot().findall('.//ymax')[0].text)\n",
        "    image = Image.open(path)\n",
        "    image = image.crop((xmin, ymin, xmax, ymax))\n",
        "    image = image.convert('RGB')\n",
        "    image.save(newpath)\n",
        "\n",
        "def crop_images():\n",
        "    breeds = os.listdir(data_dir)\n",
        "    annotations = os.listdir(annotations_dir)\n",
        "\n",
        "    print('breeds: ', len(breeds), 'annotations: ', len(annotations))\n",
        "\n",
        "    total_images = 0\n",
        "\n",
        "    for breed in breeds:\n",
        "        dir_list = os.listdir(data_dir + breed)\n",
        "        annotations_dir_list = os.listdir(annotations_dir + breed)\n",
        "        img_list = [data_dir + breed + '/' + i for i in dir_list]\n",
        "        os.makedirs(cropped_dir + breed)\n",
        "\n",
        "        for file in img_list:\n",
        "            annotation_path = annotations_dir + breed + '/' + os.path.basename(file[:-4])\n",
        "            newpath = cropped_dir + breed + '/' + os.path.basename(file)\n",
        "            save_cropped_img(file, annotation_path, newpath)\n",
        "            total_images += 1\n",
        "\n",
        "    print(\"total images cropped\", total_images)\n",
        "\n",
        "crop_images()"
      ],
      "metadata": {
        "id": "TRGZNNnfi_BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        brightness_range=[0.9,1.1],\n",
        "        horizontal_flip=True,\n",
        "        validation_split=testsplit,\n",
        "        preprocessing_function=preprocess_input\n",
        ")\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        cropped_dir,\n",
        "        target_size=(targetx, targety),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        seed=seed,\n",
        "        subset=\"training\"\n",
        ")\n",
        "test_generator = datagen.flow_from_directory(\n",
        "        cropped_dir,\n",
        "        target_size=(targetx, targety),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False,\n",
        "        seed=seed,\n",
        "        subset=\"validation\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Txi32-Oz-MDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = train_generator.filepaths[np.random.random_integers(low=0, high=train_generator.samples)]\n",
        "print(img)\n",
        "img = mpimg.imread(img)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "RyV7hno5-ijY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('dog_breed_classifier.h5',\n",
        "                             monitor='val_accuracy',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1,\n",
        "                             mode='auto',\n",
        "                             save_weights_only=False,\n",
        "                             period=1)\n",
        "tensorboard = TensorBoard(log_dir=\"./logs-\"+dt.datetime.now().strftime(\"%m%d%Y%H%M%S\"),\n",
        "                            histogram_freq=0,\n",
        "                            batch_size=batch_size,\n",
        "                            write_graph=False,\n",
        "                            update_freq='epoch')\n",
        "\n",
        "def epoch_end(epoch, logs):\n",
        "    message = \"End of epoch \"+str(epoch)+\". Learning rate: \"+str(K.eval(model.optimizer.lr))\n",
        "    os.system('echo '+message)\n",
        "\n",
        "def epoch_begin(epoch, logs):\n",
        "    print(\"Learning rate: \", K.eval(model.optimizer.lr))\n",
        "\n",
        "def train_begin(logs):\n",
        "    os.system(\"echo Beginning training\")\n",
        "    earlystop = EarlyStopping(monitor='val_accuracy',\n",
        "                          min_delta=.0001,\n",
        "                          patience=20,\n",
        "                          verbose=1,\n",
        "                          mode='auto',\n",
        "                          baseline=None,\n",
        "                          restore_best_weights=True)\n",
        "\n",
        "reducelr = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                             factor=np.sqrt(.1),\n",
        "                             patience=5,\n",
        "                             verbose=1,\n",
        "                             mode='auto',\n",
        "                             min_delta=.0001,\n",
        "                             cooldown=0,\n",
        "                             min_lr=0.0000001)\n",
        "\n",
        "lambdacb = LambdaCallback(on_epoch_begin=epoch_begin,\n",
        "                          on_epoch_end=epoch_end,\n",
        "                          on_batch_begin=None,\n",
        "                          on_batch_end=None,\n",
        "                          on_train_begin=train_begin,\n",
        "                          on_train_end=None)\n",
        "\n"
      ],
      "metadata": {
        "id": "mMvxfOWu-mrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(targetx, targety, 3))\n",
        "base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(targetx, targety, 3))\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# x = Dropout(rate = .2)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(1280, activation='relu',  kernel_initializer=glorot_uniform(seed), bias_initializer='zeros')(x)\n",
        "# x = Dropout(rate = .2)(x)\n",
        "x = BatchNormalization()(x)\n",
        "predictions = Dense(classes, activation='softmax', kernel_initializer='random_uniform', bias_initializer='zeros')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "optimizer = Adam(lr=learning_rate)\n",
        "# optimizer = RMSprop(lr=learning_rate)\n",
        "\n",
        "loss = \"categorical_crossentropy\"\n",
        "# loss = \"kullback_leibler_divergence\"\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "# for layer in model.layers[-2:]:\n",
        "#     layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "for i, layer in enumerate(model.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "Aap49Nkb-4G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Training and test accuracy')\n",
        "plt.plot(params.epoch, params.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(params.epoch, params.history['val_accuracy'], label='Test accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Training and test loss')\n",
        "plt.plot(params.epoch, params.history['loss'], label='Training loss')\n",
        "plt.plot(params.epoch, params.history['val_loss'], label='Test loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x0PuYe4y_De3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly test an image from the test set\n",
        "# model.load_weights('dog_breed_classifier.h5')\n",
        "\n",
        "imageno=np.random.random_integers(low=0, high=test_generator.samples)\n",
        "\n",
        "name = test_generator.filepaths[imageno]\n",
        "print(name)\n",
        "plt.imshow(mpimg.imread(name))\n",
        "\n",
        "img = Image.open(test_generator.filepaths[imageno]).resize((targetx, targety))\n",
        "probabilities = model.predict(preprocess_input(np.expand_dims(img, axis=0)))\n",
        "breed_list = tuple(zip(test_generator.class_indices.values(), test_generator.class_indices.keys()))\n",
        "\n",
        "for i in probabilities[0].argsort()[-5:][::-1]:\n",
        "    print(probabilities[0][i], \"  :  \" , breed_list[i])"
      ],
      "metadata": {
        "id": "jjRa5XKT_JB0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}